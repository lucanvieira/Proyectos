{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías importadas correctamente\n",
      "    Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
      "0  58138.0        0         0       58       635         88              546   \n",
      "1  46344.0        1         1       38        11          1                6   \n",
      "2  71613.0        0         0       26       426         49              127   \n",
      "3  26646.0        1         0       26        11          4               20   \n",
      "4  58293.0        1         0       94       173         43              118   \n",
      "\n",
      "   MntFishProducts  MntSweetProducts  MntGoldProds  ...  marital_Together  \\\n",
      "0              172                88            88  ...                 0   \n",
      "1                2                 1             6  ...                 0   \n",
      "2              111                21            42  ...                 1   \n",
      "3               10                 3             5  ...                 1   \n",
      "4               46                27            15  ...                 0   \n",
      "\n",
      "   marital_Widow  education_2n Cycle  education_Basic  education_Graduation  \\\n",
      "0              0                   0                0                     1   \n",
      "1              0                   0                0                     1   \n",
      "2              0                   0                0                     1   \n",
      "3              0                   0                0                     1   \n",
      "4              0                   0                0                     0   \n",
      "\n",
      "   education_Master  education_PhD  MntTotal  MntRegularProds  \\\n",
      "0                 0              0      1529             1441   \n",
      "1                 0              0        21               15   \n",
      "2                 0              0       734              692   \n",
      "3                 0              0        48               43   \n",
      "4                 0              1       407              392   \n",
      "\n",
      "   AcceptedCmpOverall  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   0  \n",
      "4                   0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "Tipos de datos por columna:\n",
      "Income                  float64\n",
      "Kidhome                   int64\n",
      "Teenhome                  int64\n",
      "Recency                   int64\n",
      "MntWines                  int64\n",
      "MntFruits                 int64\n",
      "MntMeatProducts           int64\n",
      "MntFishProducts           int64\n",
      "MntSweetProducts          int64\n",
      "MntGoldProds              int64\n",
      "NumDealsPurchases         int64\n",
      "NumWebPurchases           int64\n",
      "NumCatalogPurchases       int64\n",
      "NumStorePurchases         int64\n",
      "NumWebVisitsMonth         int64\n",
      "AcceptedCmp3              int64\n",
      "AcceptedCmp4              int64\n",
      "AcceptedCmp5              int64\n",
      "AcceptedCmp1              int64\n",
      "AcceptedCmp2              int64\n",
      "Complain                  int64\n",
      "Z_CostContact             int64\n",
      "Z_Revenue                 int64\n",
      "Response                  int64\n",
      "Age                       int64\n",
      "Customer_Days             int64\n",
      "marital_Divorced          int64\n",
      "marital_Married           int64\n",
      "marital_Single            int64\n",
      "marital_Together          int64\n",
      "marital_Widow             int64\n",
      "education_2n Cycle        int64\n",
      "education_Basic           int64\n",
      "education_Graduation      int64\n",
      "education_Master          int64\n",
      "education_PhD             int64\n",
      "MntTotal                  int64\n",
      "MntRegularProds           int64\n",
      "AcceptedCmpOverall        int64\n",
      "dtype: object\n",
      "\n",
      "Información completa del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2205 entries, 0 to 2204\n",
      "Data columns (total 39 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Income                2205 non-null   float64\n",
      " 1   Kidhome               2205 non-null   int64  \n",
      " 2   Teenhome              2205 non-null   int64  \n",
      " 3   Recency               2205 non-null   int64  \n",
      " 4   MntWines              2205 non-null   int64  \n",
      " 5   MntFruits             2205 non-null   int64  \n",
      " 6   MntMeatProducts       2205 non-null   int64  \n",
      " 7   MntFishProducts       2205 non-null   int64  \n",
      " 8   MntSweetProducts      2205 non-null   int64  \n",
      " 9   MntGoldProds          2205 non-null   int64  \n",
      " 10  NumDealsPurchases     2205 non-null   int64  \n",
      " 11  NumWebPurchases       2205 non-null   int64  \n",
      " 12  NumCatalogPurchases   2205 non-null   int64  \n",
      " 13  NumStorePurchases     2205 non-null   int64  \n",
      " 14  NumWebVisitsMonth     2205 non-null   int64  \n",
      " 15  AcceptedCmp3          2205 non-null   int64  \n",
      " 16  AcceptedCmp4          2205 non-null   int64  \n",
      " 17  AcceptedCmp5          2205 non-null   int64  \n",
      " 18  AcceptedCmp1          2205 non-null   int64  \n",
      " 19  AcceptedCmp2          2205 non-null   int64  \n",
      " 20  Complain              2205 non-null   int64  \n",
      " 21  Z_CostContact         2205 non-null   int64  \n",
      " 22  Z_Revenue             2205 non-null   int64  \n",
      " 23  Response              2205 non-null   int64  \n",
      " 24  Age                   2205 non-null   int64  \n",
      " 25  Customer_Days         2205 non-null   int64  \n",
      " 26  marital_Divorced      2205 non-null   int64  \n",
      " 27  marital_Married       2205 non-null   int64  \n",
      " 28  marital_Single        2205 non-null   int64  \n",
      " 29  marital_Together      2205 non-null   int64  \n",
      " 30  marital_Widow         2205 non-null   int64  \n",
      " 31  education_2n Cycle    2205 non-null   int64  \n",
      " 32  education_Basic       2205 non-null   int64  \n",
      " 33  education_Graduation  2205 non-null   int64  \n",
      " 34  education_Master      2205 non-null   int64  \n",
      " 35  education_PhD         2205 non-null   int64  \n",
      " 36  MntTotal              2205 non-null   int64  \n",
      " 37  MntRegularProds       2205 non-null   int64  \n",
      " 38  AcceptedCmpOverall    2205 non-null   int64  \n",
      "dtypes: float64(1), int64(38)\n",
      "memory usage: 672.0 KB\n",
      "None\n",
      "\n",
      "Resumen de datos numéricos:\n",
      "              Income      Kidhome     Teenhome      Recency     MntWines  \\\n",
      "count    2205.000000  2205.000000  2205.000000  2205.000000  2205.000000   \n",
      "mean    51622.094785     0.442177     0.506576    49.009070   306.164626   \n",
      "std     20713.063826     0.537132     0.544380    28.932111   337.493839   \n",
      "min      1730.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%     35196.000000     0.000000     0.000000    24.000000    24.000000   \n",
      "50%     51287.000000     0.000000     0.000000    49.000000   178.000000   \n",
      "75%     68281.000000     1.000000     1.000000    74.000000   507.000000   \n",
      "max    113734.000000     2.000000     2.000000    99.000000  1493.000000   \n",
      "\n",
      "         MntFruits  MntMeatProducts  MntFishProducts  MntSweetProducts  \\\n",
      "count  2205.000000      2205.000000      2205.000000       2205.000000   \n",
      "mean     26.403175       165.312018        37.756463         27.128345   \n",
      "std      39.784484       217.784507        54.824635         41.130468   \n",
      "min       0.000000         0.000000         0.000000          0.000000   \n",
      "25%       2.000000        16.000000         3.000000          1.000000   \n",
      "50%       8.000000        68.000000        12.000000          8.000000   \n",
      "75%      33.000000       232.000000        50.000000         34.000000   \n",
      "max     199.000000      1725.000000       259.000000        262.000000   \n",
      "\n",
      "       MntGoldProds  ...  marital_Together  marital_Widow  education_2n Cycle  \\\n",
      "count   2205.000000  ...       2205.000000    2205.000000         2205.000000   \n",
      "mean      44.057143  ...          0.257596       0.034467            0.089796   \n",
      "std       51.736211  ...          0.437410       0.182467            0.285954   \n",
      "min        0.000000  ...          0.000000       0.000000            0.000000   \n",
      "25%        9.000000  ...          0.000000       0.000000            0.000000   \n",
      "50%       25.000000  ...          0.000000       0.000000            0.000000   \n",
      "75%       56.000000  ...          1.000000       0.000000            0.000000   \n",
      "max      321.000000  ...          1.000000       1.000000            1.000000   \n",
      "\n",
      "       education_Basic  education_Graduation  education_Master  education_PhD  \\\n",
      "count      2205.000000           2205.000000       2205.000000    2205.000000   \n",
      "mean          0.024490              0.504762          0.165079       0.215873   \n",
      "std           0.154599              0.500091          0.371336       0.411520   \n",
      "min           0.000000              0.000000          0.000000       0.000000   \n",
      "25%           0.000000              0.000000          0.000000       0.000000   \n",
      "50%           0.000000              1.000000          0.000000       0.000000   \n",
      "75%           0.000000              1.000000          0.000000       0.000000   \n",
      "max           1.000000              1.000000          1.000000       1.000000   \n",
      "\n",
      "          MntTotal  MntRegularProds  AcceptedCmpOverall  \n",
      "count  2205.000000      2205.000000          2205.00000  \n",
      "mean    562.764626       518.707483             0.29932  \n",
      "std     575.936911       553.847248             0.68044  \n",
      "min       4.000000      -283.000000             0.00000  \n",
      "25%      56.000000        42.000000             0.00000  \n",
      "50%     343.000000       288.000000             0.00000  \n",
      "75%     964.000000       884.000000             0.00000  \n",
      "max    2491.000000      2458.000000             4.00000  \n",
      "\n",
      "[8 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR LIBRERIAS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Configuració estètica\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr, pearsonr, shapiro\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import shapiro\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import numpy as np\n",
    "# Configuración de estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")\n",
    "\n",
    "\n",
    "# Si el archivo usa otro separador como punto y coma\n",
    "df = pd.read_csv(\n",
    "    r\"C:*\\ifood_df.csv\",\n",
    "    sep=',',  # o el delimitador que corresponda\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(df.head())\n",
    "\n",
    "print(\"Tipos de datos por columna:\")\n",
    "print(df.dtypes) \n",
    "# Información detallada\n",
    "print(\"\\nInformación completa del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Estadísticas descriptivas por tipo de dato\n",
    "print(\"\\nResumen de datos numéricos:\")\n",
    "print(df.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e122aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiar tipo de la tabla income porque si hago la integración con power bi me viene con problemas\n",
    "\n",
    "df[\"Income\"] = df[\"Income\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "848993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÉTODO REUTILIZABLE PARA CUALQUIER GRUPO DE COLUMNAS DUMMY\n",
    "def convert_dummy_to_category(df, column_prefix):\n",
    "    \"\"\"\n",
    "    Convierte columnas dummy con un prefijo común en una columna categórica\n",
    "    \"\"\"\n",
    "    # Encontrar todas las columnas que empiezan con el prefijo\n",
    "    dummy_columns = [col for col in df.columns if col.startswith(column_prefix)]\n",
    "    \n",
    "    if not dummy_columns:\n",
    "        print(f\"No se encontraron columnas con el prefijo: {column_prefix}\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"Convirtiendo {len(dummy_columns)} columnas: {dummy_columns}\")\n",
    "    \n",
    "    # Crear la nueva columna categórica\n",
    "    def get_category(row):\n",
    "        for col in dummy_columns:\n",
    "            if row[col] == 1:\n",
    "                return col.replace(f'{column_prefix}_', '')\n",
    "        return 'Unknown'\n",
    "    \n",
    "    new_column_name = column_prefix.replace('_', '')  # Ej: 'education' en lugar de 'education_'\n",
    "    df[new_column_name] = df.apply(get_category, axis=1)\n",
    "    \n",
    "    # Mostrar distribución\n",
    "    print(f\"\\nDistribución de {new_column_name}:\")\n",
    "    print(df[new_column_name].value_counts())\n",
    "    \n",
    "    return df, dummy_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ef883cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas después de la transformación:\n",
      "   education_2n Cycle  education_Basic  education_Graduation  \\\n",
      "0                   0                0                     1   \n",
      "1                   0                0                     1   \n",
      "2                   0                0                     1   \n",
      "3                   0                0                     1   \n",
      "4                   0                0                     0   \n",
      "\n",
      "   education_Master  education_PhD Education_Level  MntTotal  \n",
      "0                 0              0      Graduation      1529  \n",
      "1                 0              0      Graduation        21  \n",
      "2                 0              0      Graduation       734  \n",
      "3                 0              0      Graduation        48  \n",
      "4                 0              1             PhD       407  \n"
     ]
    }
   ],
   "source": [
    "# Esta es la solución más robusta y eficiente para tranformar la COLUMNA EDUCATION:\n",
    "\n",
    "education_columns = ['education_2n Cycle', 'education_Basic', 'education_Graduation', 'education_Master', 'education_PhD']\n",
    "\n",
    "# Método más simple y confiable\n",
    "def get_education_level(row):\n",
    "    for col in education_columns:\n",
    "        if row[col] == 1:\n",
    "            return col.replace('education_', '')\n",
    "    return 'Unknown'  # Para casos donde no hay ningún 1\n",
    "\n",
    "df['Education_Level'] = df.apply(get_education_level, axis=1)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Primeras filas después de la transformación:\")\n",
    "print(df[education_columns + ['Education_Level', 'MntTotal']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98f4b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas con estado civil:\n",
      "   marital_Divorced  marital_Married  marital_Single  marital_Together  \\\n",
      "0                 0                0               1                 0   \n",
      "1                 0                0               1                 0   \n",
      "2                 0                0               0                 1   \n",
      "3                 0                0               0                 1   \n",
      "4                 0                1               0                 0   \n",
      "5                 0                0               0                 1   \n",
      "6                 1                0               0                 0   \n",
      "7                 0                1               0                 0   \n",
      "8                 0                0               0                 1   \n",
      "9                 0                0               0                 1   \n",
      "\n",
      "   marital_Widow Marital_Status  \n",
      "0              0         Single  \n",
      "1              0         Single  \n",
      "2              0       Together  \n",
      "3              0       Together  \n",
      "4              0        Married  \n",
      "5              0       Together  \n",
      "6              0       Divorced  \n",
      "7              0        Married  \n",
      "8              0       Together  \n",
      "9              0       Together  \n"
     ]
    }
   ],
   "source": [
    "# Lista de columnas de estado civil\n",
    "marital_columns = ['marital_Divorced', 'marital_Married', 'marital_Single', 'marital_Together', 'marital_Widow']\n",
    "\n",
    "# Aplicar el mismo método que usamos para educación\n",
    "def get_marital_status(row):\n",
    "    for col in marital_columns:\n",
    "        if row[col] == 1:\n",
    "            return col.replace('marital_', '')\n",
    "    return 'Unknown'\n",
    "\n",
    "df['Marital_Status'] = df.apply(get_marital_status, axis=1)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Primeras filas con estado civil:\")\n",
    "print(df[marital_columns + ['Marital_Status']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "772323fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original: (2205, 41)\n",
      "DataFrame limpio: (2205, 31)\n",
      "Columnas eliminadas: 10\n",
      "\n",
      "🎯 NUEVAS COLUMNAS CREADAS:\n",
      "✅ Education_Level\n",
      "✅ Marital_Status\n",
      "\n",
      "📋 COLUMNAS FINALES EN EL DATASET LIMPIO:\n",
      "['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response', 'Age', 'Customer_Days', 'MntTotal', 'MntRegularProds', 'AcceptedCmpOverall', 'Education_Level', 'Marital_Status']\n",
      "\n",
      "📊 INFORMACIÓN DEL DATASET LIMPIO:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2205 entries, 0 to 2204\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Income               2205 non-null   int32 \n",
      " 1   Kidhome              2205 non-null   int64 \n",
      " 2   Teenhome             2205 non-null   int64 \n",
      " 3   Recency              2205 non-null   int64 \n",
      " 4   MntWines             2205 non-null   int64 \n",
      " 5   MntFruits            2205 non-null   int64 \n",
      " 6   MntMeatProducts      2205 non-null   int64 \n",
      " 7   MntFishProducts      2205 non-null   int64 \n",
      " 8   MntSweetProducts     2205 non-null   int64 \n",
      " 9   MntGoldProds         2205 non-null   int64 \n",
      " 10  NumDealsPurchases    2205 non-null   int64 \n",
      " 11  NumWebPurchases      2205 non-null   int64 \n",
      " 12  NumCatalogPurchases  2205 non-null   int64 \n",
      " 13  NumStorePurchases    2205 non-null   int64 \n",
      " 14  NumWebVisitsMonth    2205 non-null   int64 \n",
      " 15  AcceptedCmp3         2205 non-null   int64 \n",
      " 16  AcceptedCmp4         2205 non-null   int64 \n",
      " 17  AcceptedCmp5         2205 non-null   int64 \n",
      " 18  AcceptedCmp1         2205 non-null   int64 \n",
      " 19  AcceptedCmp2         2205 non-null   int64 \n",
      " 20  Complain             2205 non-null   int64 \n",
      " 21  Z_CostContact        2205 non-null   int64 \n",
      " 22  Z_Revenue            2205 non-null   int64 \n",
      " 23  Response             2205 non-null   int64 \n",
      " 24  Age                  2205 non-null   int64 \n",
      " 25  Customer_Days        2205 non-null   int64 \n",
      " 26  MntTotal             2205 non-null   int64 \n",
      " 27  MntRegularProds      2205 non-null   int64 \n",
      " 28  AcceptedCmpOverall   2205 non-null   int64 \n",
      " 29  Education_Level      2205 non-null   object\n",
      " 30  Marital_Status       2205 non-null   object\n",
      "dtypes: int32(1), int64(28), object(2)\n",
      "memory usage: 525.5+ KB\n",
      "None\n",
      "\n",
      "📈 DISTRIBUCIÓN DE LAS NUEVAS VARIABLES:\n",
      "\n",
      "Education_Level:\n",
      "Education_Level\n",
      "Graduation    1113\n",
      "PhD            476\n",
      "Master         364\n",
      "2n Cycle       198\n",
      "Basic           54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Marital_Status:\n",
      "Marital_Status\n",
      "Married     854\n",
      "Together    568\n",
      "Single      477\n",
      "Divorced    230\n",
      "Widow        76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las columnas dummy originales\n",
    "columns_to_drop = ['education_2n Cycle', 'education_Basic', 'education_Graduation', 'education_Master', 'education_PhD'] + marital_columns \n",
    "\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"DataFrame original: {df.shape}\")\n",
    "print(f\"DataFrame limpio: {df_clean.shape}\")\n",
    "print(f\"Columnas eliminadas: {len(columns_to_drop)}\")\n",
    "\n",
    "# Mostrar las nuevas columnas creadas\n",
    "print(\"\\n🎯 NUEVAS COLUMNAS CREADAS:\")\n",
    "new_categorical_cols = ['Education_Level', 'Marital_Status']\n",
    "for col in new_categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        print(f\"✅ {col}\")\n",
    "\n",
    "# Ver la estructura final del DataFrame\n",
    "print(f\"\\n📋 COLUMNAS FINALES EN EL DATASET LIMPIO:\")\n",
    "print(df_clean.columns.tolist())\n",
    "\n",
    "# Mostrar información del DataFrame limpio\n",
    "print(f\"\\n📊 INFORMACIÓN DEL DATASET LIMPIO:\")\n",
    "print(df_clean.info())\n",
    "\n",
    "# Mostrar estadísticas de las nuevas variables categóricas\n",
    "print(f\"\\n📈 DISTRIBUCIÓN DE LAS NUEVAS VARIABLES:\")\n",
    "categorical_columns = ['Education_Level', 'Marital_Status', 'Campaign_Segment']\n",
    "for col in categorical_columns:\n",
    "    if col in df_clean.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df_clean[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf674b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VERIFICACIÓN COMPLETA DE DUPLICADOS\n",
      "==================================================\n",
      "1. Duplicados exactos (todas las columnas): 184\n",
      "\n",
      "2. Verificación de unicidad por características clave:\n",
      "   - ['Income', 'Age', 'Education_Level', 'Marital_Status']: 2002 únicos de 2205 registros\n",
      "   - ['Income', 'Kidhome', 'Teenhome', 'Age']: 1999 únicos de 2205 registros\n",
      "   - ['MntTotal', 'NumWebPurchases', 'NumStorePurchases', 'Age']: 1973 únicos de 2205 registros\n",
      "\n",
      "3. ANÁLISIS DETALLADO POR COLUMNA:\n",
      "   Income              : 1963 únicos ( 89.0%)\n",
      "   Age                 :   56 únicos (  2.5%)\n",
      "   Education_Level     :    5 únicos (  0.2%)\n",
      "   Marital_Status      :    5 únicos (  0.2%)\n",
      "   Kidhome             :    3 únicos (  0.1%)\n",
      "   Teenhome            :    3 únicos (  0.1%)\n",
      "   MntTotal            :  897 únicos ( 40.7%)\n",
      "\n",
      "4. BÚSQUEDA DE POSIBLES CLIENTES DUPLICADOS:\n",
      "   Se encontraron 397 registros con características similares\n",
      "   Grupos de posibles duplicados:\n",
      "   Número de grupos con características idénticas: 194\n",
      "\n",
      "   Ejemplos de posibles duplicados:\n",
      "    Income  Age Education_Level Marital_Status  Kidhome  Teenhome  MntTotal  \\\n",
      "8    30351   46             PhD       Together        1         0        44   \n",
      "14   82800   74             PhD         Single        0         0      1270   \n",
      "16   37760   74      Graduation       Together        0         0       289   \n",
      "22   65324   66             PhD        Married        0         1       539   \n",
      "23   40689   69      Graduation       Together        0         1       345   \n",
      "27   84618   55             PhD        Married        0         0      1672   \n",
      "\n",
      "    Recency  \n",
      "8        19  \n",
      "14       23  \n",
      "16       20  \n",
      "22        0  \n",
      "23       69  \n",
      "27       96  \n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 VERIFICACIÓN COMPLETA DE DUPLICADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Duplicados exactos en todas las columnas\n",
    "duplicados_exactos = df_clean.duplicated().sum()\n",
    "print(f\"1. Duplicados exactos (todas las columnas): {duplicados_exactos}\")\n",
    "\n",
    "# 2. Verificar combinaciones únicas que deberían identificar a cada cliente\n",
    "print(f\"\\n2. Verificación de unicidad por características clave:\")\n",
    "\n",
    "# Combinaciones que deberían ser únicas para cada cliente\n",
    "combinaciones_unicas = [\n",
    "    ['Income', 'Age', 'Education_Level', 'Marital_Status'],\n",
    "    ['Income', 'Kidhome', 'Teenhome', 'Age'],\n",
    "    ['MntTotal', 'NumWebPurchases', 'NumStorePurchases', 'Age']\n",
    "]\n",
    "\n",
    "for combo in combinaciones_unicas:\n",
    "    combo_existente = [col for col in combo if col in df_clean.columns]\n",
    "    if combo_existente:\n",
    "        valores_unicos = df_clean[combo_existente].drop_duplicates().shape[0]\n",
    "        total_registros = len(df_clean)\n",
    "        print(f\"   - {combo_existente}: {valores_unicos} únicos de {total_registros} registros\")\n",
    "\n",
    "# 3. Análisis detallado de duplicados por columna\n",
    "print(f\"\\n3. ANÁLISIS DETALLADO POR COLUMNA:\")\n",
    "columnas_analizar = ['Income', 'Age', 'Education_Level', 'Marital_Status', 'Kidhome', 'Teenhome', 'MntTotal']\n",
    "for col in columnas_analizar:\n",
    "    if col in df_clean.columns:\n",
    "        valores_unicos = df_clean[col].nunique()\n",
    "        total_registros = len(df_clean)\n",
    "        porcentaje = (valores_unicos / total_registros) * 100\n",
    "        print(f\"   {col:<20}: {valores_unicos:>4} únicos ({porcentaje:5.1f}%)\")\n",
    "\n",
    "# 4. Buscar posibles clientes duplicados\n",
    "print(f\"\\n4. BÚSQUEDA DE POSIBLES CLIENTES DUPLICADOS:\")\n",
    "caracteristicas_cliente = ['Income', 'Age', 'Education_Level', 'Marital_Status', 'Kidhome', 'Teenhome']\n",
    "\n",
    "if all(col in df_clean.columns for col in caracteristicas_cliente):\n",
    "    # Encontrar clientes con mismas características demográficas\n",
    "    clientes_similares = df_clean[df_clean.duplicated(subset=caracteristicas_cliente, keep=False)]\n",
    "    \n",
    "    if len(clientes_similares) > 0:\n",
    "        print(f\"   Se encontraron {len(clientes_similares)} registros con características similares\")\n",
    "        print(f\"   Grupos de posibles duplicados:\")\n",
    "        \n",
    "        # Contar cuántos grupos de duplicados hay\n",
    "        grupos_duplicados = clientes_similares.groupby(caracteristicas_cliente).size()\n",
    "        print(f\"   Número de grupos con características idénticas: {len(grupos_duplicados)}\")\n",
    "        \n",
    "        # Mostrar algunos ejemplos\n",
    "        print(f\"\\n   Ejemplos de posibles duplicados:\")\n",
    "        print(clientes_similares[caracteristicas_cliente + ['MntTotal', 'Recency']].head(6))\n",
    "    else:\n",
    "        print(f\"   ✅ No se encontraron clientes con características demográficas idénticas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1cc0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ANÁLISIS DETALLADO DE DUPLICADOS\n",
      "==================================================\n",
      "Income                   : 1963 únicos ( 89.0%)\n",
      "Kidhome                  :    3 únicos (  0.1%)\n",
      "Teenhome                 :    3 únicos (  0.1%)\n",
      "Recency                  :  100 únicos (  4.5%)\n",
      "MntWines                 :  775 únicos ( 35.1%)\n",
      "MntFruits                :  158 únicos (  7.2%)\n",
      "MntMeatProducts          :  551 únicos ( 25.0%)\n",
      "MntFishProducts          :  182 únicos (  8.3%)\n",
      "MntSweetProducts         :  176 únicos (  8.0%)\n",
      "MntGoldProds             :  212 únicos (  9.6%)\n",
      "NumDealsPurchases        :   15 únicos (  0.7%)\n",
      "NumWebPurchases          :   15 únicos (  0.7%)\n",
      "NumCatalogPurchases      :   13 únicos (  0.6%)\n",
      "NumStorePurchases        :   14 únicos (  0.6%)\n",
      "NumWebVisitsMonth        :   16 únicos (  0.7%)\n",
      "AcceptedCmp3             :    2 únicos (  0.1%)\n",
      "AcceptedCmp4             :    2 únicos (  0.1%)\n",
      "AcceptedCmp5             :    2 únicos (  0.1%)\n",
      "AcceptedCmp1             :    2 únicos (  0.1%)\n",
      "AcceptedCmp2             :    2 únicos (  0.1%)\n",
      "Complain                 :    2 únicos (  0.1%)\n",
      "Z_CostContact            :    1 únicos (  0.0%)\n",
      "Z_Revenue                :    1 únicos (  0.0%)\n",
      "Response                 :    2 únicos (  0.1%)\n",
      "Age                      :   56 únicos (  2.5%)\n",
      "Customer_Days            :  662 únicos ( 30.0%)\n",
      "MntTotal                 :  897 únicos ( 40.7%)\n",
      "MntRegularProds          :  974 únicos ( 44.2%)\n",
      "AcceptedCmpOverall       :    5 únicos (  0.2%)\n",
      "Education_Level          :    5 únicos (  0.2%)\n",
      "Marital_Status           :    5 únicos (  0.2%)\n",
      "\n",
      "🚨 COLUMNAS CON POSIBLES PROBLEMAS:\n",
      "   - Kidhome: 3 valores únicos\n",
      "   - Teenhome: 3 valores únicos\n",
      "   - Recency: 100 valores únicos\n",
      "   - MntFruits: 158 valores únicos\n",
      "   - MntFishProducts: 182 valores únicos\n",
      "   - MntSweetProducts: 176 valores únicos\n",
      "   - MntGoldProds: 212 valores únicos\n",
      "   - NumDealsPurchases: 15 valores únicos\n",
      "   - NumWebPurchases: 15 valores únicos\n",
      "   - NumCatalogPurchases: 13 valores únicos\n",
      "   - NumStorePurchases: 14 valores únicos\n",
      "   - NumWebVisitsMonth: 16 valores únicos\n",
      "   - AcceptedCmp3: 2 valores únicos\n",
      "   - AcceptedCmp4: 2 valores únicos\n",
      "   - AcceptedCmp5: 2 valores únicos\n",
      "   - AcceptedCmp1: 2 valores únicos\n",
      "   - AcceptedCmp2: 2 valores únicos\n",
      "   - Complain: 2 valores únicos\n",
      "   - Z_CostContact: 1 valores únicos\n",
      "   - Z_Revenue: 1 valores únicos\n",
      "   - Response: 2 valores únicos\n",
      "   - Age: 56 valores únicos\n",
      "   - AcceptedCmpOverall: 5 valores únicos\n",
      "   - Education_Level: 5 valores únicos\n",
      "   - Marital_Status: 5 valores únicos\n"
     ]
    }
   ],
   "source": [
    "# Función para análisis profundo de duplicados\n",
    "def analizar_duplicados_detallado(df):\n",
    "    print(\"📊 ANÁLISIS DETALLADO DE DUPLICADOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Verificar por cada tipo de columna\n",
    "    todas_columnas = df.columns.tolist()\n",
    "    \n",
    "    for col in todas_columnas:\n",
    "        valores_unicos = df[col].nunique()\n",
    "        total_registros = len(df)\n",
    "        porcentaje_unicos = (valores_unicos / total_registros) * 100\n",
    "        \n",
    "        print(f\"{col:<25}: {valores_unicos:>4} únicos ({porcentaje_unicos:5.1f}%)\")\n",
    "    \n",
    "    # Identificar columnas con posible problema de duplicados\n",
    "    print(f\"\\n🚨 COLUMNAS CON POSIBLES PROBLEMAS:\")\n",
    "    for col in todas_columnas:\n",
    "        if df[col].nunique() < len(df) * 0.1:  # Menos del 10% de valores únicos\n",
    "            print(f\"   - {col}: {df[col].nunique()} valores únicos\")\n",
    "\n",
    "# Ejecutar análisis detallado\n",
    "analizar_duplicados_detallado(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0323b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 PROCEDIMIENTO DE LIMPIEZA DE DUPLICADOS\n",
      "==================================================\n",
      "Registros originales: 2205\n",
      "Duplicados exactos eliminados: 184\n",
      "Registros restantes: 2021\n"
     ]
    }
   ],
   "source": [
    "print(\"🧹 PROCEDIMIENTO DE LIMPIEZA DE DUPLICADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Guardar el estado original\n",
    "registros_originales = len(df_clean)\n",
    "print(f\"Registros originales: {registros_originales}\")\n",
    "\n",
    "# 1. ELIMINAR DUPLICADOS EXACTOS (mantener el primero)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "duplicados_eliminados = registros_originales - len(df_clean)\n",
    "print(f\"Duplicados exactos eliminados: {duplicados_eliminados}\")\n",
    "print(f\"Registros restantes: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe1a559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 CLIENTES CON MISMAS CARACTERÍSTICAS DEMOGRÁFICAS: 38\n",
      "Número de grupos con características idénticas: 19\n",
      "\n",
      "📊 GRUPOS MÁS GRANDES (primeros 3):\n",
      "Grupo 1: 2 clientes con características: (19514, 52, 'Graduation', 'Married', 1, 1)\n",
      "Grupo 2: 2 clientes con características: (52278, 57, 'PhD', 'Widow', 0, 1)\n",
      "Grupo 3: 2 clientes con características: (82347, 63, '2n Cycle', 'Married', 0, 0)\n",
      "\n",
      "📋 EJEMPLOS DE CLIENTES CON MISMAS CARACTERÍSTICAS:\n",
      "     Income  Age Education_Level Marital_Status  Kidhome  Teenhome  MntTotal  \\\n",
      "8     30351   46             PhD       Together        1         0        44   \n",
      "78    81361   33      Graduation       Divorced        0         0       702   \n",
      "130   65104   44          Master       Together        0         1      1003   \n",
      "182   31353   43      Graduation        Married        1         1        24   \n",
      "242   63342   59             PhD       Together        0         1      1080   \n",
      "357   38578   48             PhD         Single        1         1        70   \n",
      "\n",
      "     Recency  Response  \n",
      "8         19         1  \n",
      "78        18         0  \n",
      "130        4         1  \n",
      "182       24         0  \n",
      "242       48         0  \n",
      "357        2         1  \n"
     ]
    }
   ],
   "source": [
    "# 2. Análisis de duplicados por características demográficas (CORREGIDO)\n",
    "caracteristicas_unicas = ['Income', 'Age', 'Education_Level', 'Marital_Status', 'Kidhome', 'Teenhome']\n",
    "\n",
    "# Encontrar posibles duplicados restantes\n",
    "duplicados_demograficos = df_clean[df_clean.duplicated(subset=caracteristicas_unicas, keep=False)]\n",
    "print(f\"\\n🔍 CLIENTES CON MISMAS CARACTERÍSTICAS DEMOGRÁFICAS: {len(duplicados_demograficos)}\")\n",
    "\n",
    "if len(duplicados_demograficos) > 0:\n",
    "    # Usar value_counts() en lugar de groupby().items()\n",
    "    grupos_tamanos = duplicados_demograficos.groupby(caracteristicas_unicas).size()\n",
    "    print(f\"Número de grupos con características idénticas: {len(grupos_tamanos)}\")\n",
    "    \n",
    "    # Mostrar los grupos más grandes\n",
    "    print(f\"\\n📊 GRUPOS MÁS GRANDES (primeros 3):\")\n",
    "    for i, (grupo, tamano) in enumerate(grupos_tamanos.sort_values(ascending=False).head(3).items()):\n",
    "        print(f\"Grupo {i+1}: {tamano} clientes con características: {grupo}\")\n",
    "    \n",
    "    # Mostrar ejemplos de estos duplicados\n",
    "    print(f\"\\n📋 EJEMPLOS DE CLIENTES CON MISMAS CARACTERÍSTICAS:\")\n",
    "    ejemplos = duplicados_demograficos[caracteristicas_unicas + ['MntTotal', 'Recency', 'Response']].head(6)\n",
    "    print(ejemplos)\n",
    "else:\n",
    "    print(\"✅ No hay clientes con características demográficas idénticas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e804509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 DECISIÓN FINAL SOBRE DUPLICADOS:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ℹ️ Se encontraron clientes con características similares pero:\n",
      "   - Pueden ser clientes diferentes con coincidencias demográficas\n",
      "   - Vamos a mantener todos los registros y crear IDs únicos\n",
      "   - Esto preserva la integridad de los datos de comportamiento\n",
      "\n",
      "🆔 CREANDO COLUMNA ID ÚNICA...\n",
      "✅ IDs únicos creados: 2021\n",
      "✅ Total de registros: 2021\n",
      "🔍 Verificación: True\n"
     ]
    }
   ],
   "source": [
    "# BASADO EN EL ANÁLISSO, PROCEDEMOS CON LA SIGUIENTE ESTRATEGIA:\n",
    "\n",
    "print(f\"\\n🎯 DECISIÓN FINAL SOBRE DUPLICADOS:\")\n",
    "\n",
    "if len(duplicados_demograficos) == 0:\n",
    "    print(\"✅ No hay duplicados demográficos - Proceder con creación de IDs\")\n",
    "else:\n",
    "    print(\"ℹ️ Se encontraron clientes con características similares pero:\")\n",
    "    print(\"   - Pueden ser clientes diferentes con coincidencias demográficas\")\n",
    "    print(\"   - Vamos a mantener todos los registros y crear IDs únicos\")\n",
    "    print(\"   - Esto preserva la integridad de los datos de comportamiento\")\n",
    "\n",
    "# 4. CREAR COLUMNA ID ÚNICA (ahora que limpiamos duplicados exactos)\n",
    "print(f\"\\n🆔 CREANDO COLUMNA ID ÚNICA...\")\n",
    "\n",
    "# Opción: ID secuencial con prefijo\n",
    "df_clean['CustomerID'] = ['CUST_' + str(i+1).zfill(4) for i in range(len(df_clean))]\n",
    "\n",
    "# Verificar que no hay duplicados en el ID\n",
    "print(f\"✅ IDs únicos creados: {df_clean['CustomerID'].nunique()}\")\n",
    "print(f\"✅ Total de registros: {len(df_clean)}\")\n",
    "print(f\"🔍 Verificación: {df_clean['CustomerID'].nunique() == len(df_clean)}\")\n",
    "\n",
    "# Mover la columna ID al principio\n",
    "columnas_ordenadas = ['CustomerID'] + [col for col in df_clean.columns if col != 'CustomerID']\n",
    "df_clean = df_clean[columnas_ordenadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1cdb9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 IMPACTO DE LA LIMPIEZA EN ESTADÍSTICAS CLAVE:\n",
      "\n",
      "Comparación de estadísticas clave:\n",
      "\n",
      "Income:\n",
      "  - Media: 51687.26\n",
      "  - Mediana: 51412.00\n",
      "\n",
      "MntTotal:\n",
      "  - Media: 563.79\n",
      "  - Mediana: 343.00\n",
      "\n",
      "Response:\n",
      "  - Media: 0.15\n",
      "  - Mediana: 0.00\n",
      "  - Tasa de conversión: 15.39%\n",
      "\n",
      "Age:\n",
      "  - Media: 51.12\n",
      "  - Mediana: 50.00\n",
      "\n",
      "🎉 DATASET LIMPIO Y LISTO PARA ANÁLISIS!\n",
      "   Total de clientes únicos: 2021\n"
     ]
    }
   ],
   "source": [
    "# Análisis del impacto de la limpieza\n",
    "print(f\"\\n📊 IMPACTO DE LA LIMPIEZA EN ESTADÍSTICAS CLAVE:\")\n",
    "\n",
    "# Comparar estadísticas antes y después (aproximado)\n",
    "if duplicados_eliminados > 0:\n",
    "    stats_columns = ['Income', 'MntTotal', 'Response', 'Age']\n",
    "    print(\"\\nComparación de estadísticas clave:\")\n",
    "    for col in stats_columns:\n",
    "        if col in df_clean.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  - Media: {df_clean[col].mean():.2f}\")\n",
    "            print(f\"  - Mediana: {df_clean[col].median():.2f}\")\n",
    "            if col == 'Response':\n",
    "                print(f\"  - Tasa de conversión: {df_clean[col].mean():.2%}\")\n",
    "\n",
    "print(f\"\\n🎉 DATASET LIMPIO Y LISTO PARA ANÁLISIS!\")\n",
    "print(f\"   Total de clientes únicos: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46ad32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar columnas por bloques lógicos\n",
    "new_order = [\n",
    "    # 1️⃣ Identificación y demografía\n",
    "    'CustomerID', 'Age', 'Income', 'Education_Level', 'Marital_Status', 'Kidhome', 'Teenhome',\n",
    "    # 2️⃣ Relación con la empresa\n",
    "    'Customer_Days', 'Recency', 'Complain', 'Z_CostContact', 'Z_Revenue',\n",
    "    # 3️⃣ Consumo y gasto\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "    'MntSweetProducts', 'MntGoldProds', 'MntTotal', 'MntRegularProds',\n",
    "    # 4️⃣ Canales de compra y visitas\n",
    "    'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "    # 5️⃣ Campañas de marketing\n",
    "    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4',\n",
    "    'AcceptedCmp5', 'AcceptedCmpOverall', 'Response'\n",
    "]\n",
    "\n",
    "# Aplicar el nuevo orden\n",
    "df_clean = df_clean[new_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163661a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ARCHIVO GUARDADO EXITOSAMENTE!\n",
      "📁 Ruta: C:\\Users\\Lucan Vieira\\Documents\\GitHub\\Proyectos\\MARKETING\\Data\\digital_marketing_cleaned.csv\n",
      "📊 Filas: 2,021, Columnas: 32\n",
      "💾 Tamaño: 0.20 MB\n",
      "📅 Guardado el: 2025-10-23 16:27:44\n",
      "\n",
      "📋 PRIMERAS FILAS DEL ARCHIVO GUARDADO:\n",
      "Columnas: ['CustomerID', 'Age', 'Income', 'Education_Level', 'Marital_Status', 'Kidhome', 'Teenhome', 'Customer_Days', 'Recency', 'Complain', 'Z_CostContact', 'Z_Revenue', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'MntTotal', 'MntRegularProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmpOverall', 'Response']\n",
      "Primeras 3 filas:\n",
      "  CustomerID  Age  Income Education_Level Marital_Status  Kidhome  Teenhome  \\\n",
      "0  CUST_0001   63   58138      Graduation         Single        0         0   \n",
      "1  CUST_0002   66   46344      Graduation         Single        1         1   \n",
      "2  CUST_0003   55   71613      Graduation       Together        0         0   \n",
      "\n",
      "   Customer_Days  Recency  Complain  ...  NumCatalogPurchases  \\\n",
      "0           2822       58         0  ...                   10   \n",
      "1           2272       38         0  ...                    1   \n",
      "2           2471       26         0  ...                    2   \n",
      "\n",
      "   NumStorePurchases  NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  \\\n",
      "0                  4                  7             0             0   \n",
      "1                  2                  5             0             0   \n",
      "2                 10                  4             0             0   \n",
      "\n",
      "   AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmpOverall  Response  \n",
      "0             0             0             0                   0         1  \n",
      "1             0             0             0                   0         0  \n",
      "2             0             0             0                   0         0  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# CORRECCIÓN DE LA RUTA - AGREGANDO NOMBRE DE ARCHIVO Y EXTENSIÓN\n",
    "ruta_elegida = r\"*\\digital_marketing_cleaned.csv\"\n",
    "\n",
    "try:\n",
    "    # Asegurarnos de que el directorio existe\n",
    "    os.makedirs(os.path.dirname(ruta_elegida), exist_ok=True)\n",
    "    \n",
    "    # Guardar el DataFrame CORRECTO (df_clean)\n",
    "    df_clean.to_csv(ruta_elegida, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Verificar que se guardó correctamente\n",
    "    if os.path.exists(ruta_elegida):\n",
    "        file_size = os.path.getsize(ruta_elegida) / (1024 * 1024)  # Tamaño en MB\n",
    "        print(f\"✅ ARCHIVO GUARDADO EXITOSAMENTE!\")\n",
    "        print(f\"📁 Ruta: {ruta_elegida}\")\n",
    "        print(f\"📊 Filas: {df_clean.shape[0]:,}, Columnas: {df_clean.shape[1]}\")\n",
    "        print(f\"💾 Tamaño: {file_size:.2f} MB\")\n",
    "        print(f\"📅 Guardado el: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # Mostrar preview del archivo guardado\n",
    "        print(f\"\\n📋 PRIMERAS FILAS DEL ARCHIVO GUARDADO:\")\n",
    "        df_verificacion = pd.read_csv(ruta_elegida)\n",
    "        print(f\"Columnas: {list(df_verificacion.columns)}\")\n",
    "        print(f\"Primeras 3 filas:\")\n",
    "        print(df_verificacion.head(3))\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Error: El archivo no se pudo guardar\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al guardar: {e}\")\n",
    "    print(\"\\n💡 SOLUCIÓN ALTERNATIVA: Guardar en una ruta más simple...\")\n",
    "    \n",
    "    # Alternativa: guardar en el directorio actual\n",
    "    ruta_alternativa = \"digital_marketing_analysis_cleaned.csv\"\n",
    "    df_clean.to_csv(ruta_alternativa, index=False)\n",
    "    print(f\"✅ Guardado alternativo en: {os.path.abspath(ruta_alternativa)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
